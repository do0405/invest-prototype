# -*- coding: utf-8 -*-
# íˆ¬ì ìŠ¤í¬ë¦¬ë„ˆ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ

import os
import pandas as pd
import numpy as np
import glob
import concurrent.futures
import re
from datetime import datetime, timedelta
from scipy.stats import rankdata
from pytz import timezone

# ë””ë ‰í† ë¦¬ ìƒì„± í•¨ìˆ˜
def ensure_dir(directory):
    """ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
    if not os.path.exists(directory):
        os.makedirs(directory)
        print(f"ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±ë¨: {directory}")

# í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„± í•¨ìˆ˜
def create_required_dirs(directories=None):
    """í•„ìš”í•œ ëª¨ë“  ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        directories: ìƒì„±í•  ë””ë ‰í† ë¦¬ ëª©ë¡ (ê¸°ë³¸ê°’: None, ì´ ê²½ìš° config.pyì—ì„œ ì •ì˜ëœ ë””ë ‰í† ë¦¬ ì‚¬ìš©)
    """
    if directories is None:
        # config.pyì—ì„œ ì •ì˜ëœ ë””ë ‰í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
        from config import (
            DATA_DIR, DATA_US_DIR, RESULTS_DIR,
            RESULTS2_DIR, RESULTS_VER2_DIR, BACKUP_DIR, MARKMINERVINI_DIR
        )
        directories = [
            DATA_DIR, DATA_US_DIR, RESULTS_DIR,
            RESULTS2_DIR, RESULTS_VER2_DIR, BACKUP_DIR, MARKMINERVINI_DIR
        ]
    
    for directory in directories:
        ensure_dir(directory)

# CSV íŒŒì¼ ë³‘ë ¬ ë¡œë“œ í•¨ìˆ˜
def load_csvs_parallel(file_paths, max_workers=4):
    """CSV íŒŒì¼ë“¤ì„ ë³‘ë ¬ë¡œ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    
    Args:
        file_paths: CSV íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        max_workers: ìµœëŒ€ ë³‘ë ¬ ì‘ì—…ì ìˆ˜ (ê¸°ë³¸ê°’: 4)
        
    Returns:
        dict: {íŒŒì¼ëª…: DataFrame} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    results = {}
    
    def load_csv(file_path):
        try:
            df = pd.read_csv(file_path)
            return os.path.basename(file_path), df
        except Exception as e:
            print(f"âŒ {file_path} ë¡œë“œ ì˜¤ë¥˜: {e}")
            return os.path.basename(file_path), None
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_file = {executor.submit(load_csv, file_path): file_path for file_path in file_paths}
        for future in concurrent.futures.as_completed(future_to_file):
            file_name, df = future.result()
            if df is not None:
                results[file_name] = df
    
    return results

# ë¯¸êµ­ ì‹œì¥ ë‚ ì§œ ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜
def get_us_market_today():
    """ë¯¸êµ­ ì‹œì¥ ê¸°ì¤€ ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    
    Returns:
        datetime: ë¯¸êµ­ ë™ë¶€ ì‹œê°„ëŒ€ ê¸°ì¤€ ì˜¤ëŠ˜ ë‚ ì§œ
    """
    # ë¯¸êµ­ ë™ë¶€ ì‹œê°„ëŒ€ (ET) ì‚¬ìš©
    et_now = datetime.now(timezone('US/Eastern'))
    return et_now.date()

# í‹°ì»¤ ì •ë¦¬ í•¨ìˆ˜
def clean_tickers(tickers):
    """í‹°ì»¤ ëª©ë¡ì„ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        tickers: ì •ë¦¬í•  í‹°ì»¤ ëª©ë¡
        
    Returns:
        list: ì •ë¦¬ëœ í‹°ì»¤ ëª©ë¡
    """
    if not tickers:
        return []
    
    # None, NaN ê°’ ì œê±°
    cleaned = [t for t in tickers if t is not None and not pd.isna(t)]
    
    # ë¬¸ìì—´ ë³€í™˜ ë° ê³µë°± ì œê±°
    cleaned = [str(t).strip() for t in cleaned]
    
    # ë¹„ì •ìƒì ì¸ í‹°ì»¤ í•„í„°ë§
    filtered = []
    for ticker in cleaned:
        # ë¹ˆ ë¬¸ìì—´ì´ë‚˜ ê³µë°±ë§Œ ìˆëŠ” ê²½ìš° ì œì™¸
        if not ticker or ticker.isspace():
            continue
            
        # ìœ íš¨í•œ í‹°ì»¤ ì‹¬ë³¼ íŒ¨í„´ ê²€ì‚¬ (ì•ŒíŒŒë²³, ìˆ«ì, ì¼ë¶€ íŠ¹ìˆ˜ë¬¸ìë§Œ í—ˆìš©)
        if not all(c.isalnum() or c in '.-$^' for c in ticker):
            # ë¡œê·¸ ì‹œì‘ ë¶€ë¶„
            log_msg = f"âš ï¸ ë¹„ì •ìƒì ì¸ í‹°ì»¤ ì œì™¸: {ticker}"
            reasons = []
            
            # HTML íƒœê·¸ íŒ¨í„´ ê°ì§€
            if '<' in ticker or '>' in ticker:
                reasons.append("HTML íƒœê·¸ í¬í•¨")
            
            # CSS ìŠ¤íƒ€ì¼ ì½”ë“œ íŒ¨í„´ ê°ì§€
            css_patterns = ['{', '}', ':', ';']
            css_keywords = ['width', 'height', 'position', 'margin', 'padding', 'color', 'background', 'font', 'display', 'style']
            
            if any(p in ticker for p in css_patterns):
                reasons.append("CSS êµ¬ë¬¸ í¬í•¨")
            elif any(kw in ticker.lower() for kw in css_keywords):
                reasons.append("CSS ì†ì„± í¬í•¨")
            
            # JavaScript ì½”ë“œ íŒ¨í„´ ê°ì§€
            js_patterns = ['=', '(', ')', '[', ']', '&&', '||', '!', '?', '.']
            js_keywords = ['function', 'var', 'let', 'const', 'return', 'if', 'else', 'for', 'while', 'class', 'new', 'this', 'document', 'window']
            
            if any(p in ticker for p in js_patterns):
                reasons.append("JS êµ¬ë¬¸ í¬í•¨")
            elif any(kw in ticker.lower() for kw in js_keywords):
                reasons.append("JS í‚¤ì›Œë“œ í¬í•¨")
            elif '.className' in ticker or 'RegExp' in ticker:
                reasons.append("JS API í¬í•¨")
            
            # JavaScript ì£¼ì„ íŒ¨í„´ ê°ì§€
            if ticker.strip().startswith('//') or ticker.strip().startswith('/*') or ticker.strip().endswith('*/'):
                reasons.append("JS ì£¼ì„ í¬í•¨")
            
            # ê¸°íƒ€ ë¹„ì •ìƒ íŒ¨í„´
            if not reasons:
                reasons.append("ë¹„ì •ìƒ ë¬¸ì í¬í•¨")
            
            # ë¡œê·¸ ì¶œë ¥
            print(f"{log_msg} - ì´ìœ : {', '.join(reasons)}")
            continue
        
        # í‹°ì»¤ê°€ ë„ˆë¬´ ê¸¸ë©´ ê±°ë¶€ (ì¼ë°˜ì ì¸ í‹°ì»¤ëŠ” 1-5ì)
        if len(ticker) > 8:
            print(f"âš ï¸ ë„ˆë¬´ ê¸´ í‹°ì»¤ ì œì™¸ ({len(ticker)}ì): {ticker}")
            continue
            
        filtered.append(ticker)
    
    cleaned = filtered
    
    # ë¹ˆ ë¬¸ìì—´ ì œê±°
    cleaned = [t for t in cleaned if t]
    
    # HTML íƒœê·¸ê°€ í¬í•¨ëœ í‹°ì»¤ ì œê±°
    filtered = []
    for ticker in cleaned:
        if '<' in ticker or '>' in ticker:
            print(f"âš ï¸ HTML íƒœê·¸ê°€ í¬í•¨ëœ í‹°ì»¤ ì œì™¸: {ticker}")
            continue
        # JavaScript ì½”ë“œ íŒ¨í„´ ê°ì§€ (í•¨ìˆ˜ í˜¸ì¶œ, ë³€ìˆ˜ í• ë‹¹ ë“±)
        if '=' in ticker or '(' in ticker or ')' in ticker or '.className' in ticker or 'RegExp' in ticker:
            print(f"âš ï¸ JavaScript ì½”ë“œë¡œ ì¶”ì •ë˜ëŠ” í‹°ì»¤ ì œì™¸: {ticker}")
            continue
        # JavaScript ì£¼ì„ íŒ¨í„´ ê°ì§€
        if ticker.strip().startswith('//') or ticker.strip().startswith('/*') or ticker.strip().endswith('*/'):
            print(f"âš ï¸ JavaScript ì£¼ì„ìœ¼ë¡œ ì¶”ì •ë˜ëŠ” í‹°ì»¤ ì œì™¸: {ticker}")
            continue
        filtered.append(ticker)
    
    # ì¤‘ë³µ ì œê±°
    filtered = list(set(filtered))
    
    return filtered

# ë‚ ì§œ ë²”ìœ„ ìƒì„± í•¨ìˆ˜
def get_date_range(end_date=None, days=30):
    """ì§€ì •ëœ ì¢…ë£Œì¼ë¡œë¶€í„° ì¼ì • ê¸°ê°„ì˜ ë‚ ì§œ ë²”ìœ„ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        end_date: ì¢…ë£Œì¼ (ê¸°ë³¸ê°’: ì˜¤ëŠ˜)
        days: ì¼ìˆ˜ (ê¸°ë³¸ê°’: 30ì¼)
        
    Returns:
        tuple: (ì‹œì‘ì¼, ì¢…ë£Œì¼) í˜•íƒœì˜ íŠœí”Œ
    """
    if end_date is None:
        end_date = datetime.now().date()
    elif isinstance(end_date, str):
        end_date = datetime.strptime(end_date, '%Y-%m-%d').date()
    
    start_date = end_date - timedelta(days=days)
    
    return start_date, end_date

# í‹°ì»¤ ì¶”ì¶œ í•¨ìˆ˜
def extract_ticker_from_filename(filename):
    """íŒŒì¼ëª…ì—ì„œ í‹°ì»¤ ì‹¬ë³¼ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    
    Args:
        filename: íŒŒì¼ëª… (ì˜ˆ: 'AAPL.csv' ë˜ëŠ” 'AAPL_data.csv')
        
    Returns:
        str: í‹°ì»¤ ì‹¬ë³¼
    """
    # í™•ì¥ì ì œê±°
    base_name = os.path.splitext(filename)[0]
    
    # ì–¸ë”ìŠ¤ì½”ì–´(_) ì´í›„ ë¶€ë¶„ ì œê±°
    ticker = base_name.split('_')[0]
    
    return ticker

# S&P 500 ì¡°ê±´ í™•ì¸ í•¨ìˆ˜ëŠ” ì•„ë˜ì— í†µí•©ëœ ë²„ì „ìœ¼ë¡œ ì •ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

# ì£¼ì‹ ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜
def process_stock_data(file, data_dir, min_days=200, recent_days=200):
    """ì£¼ì‹ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        file: íŒŒì¼ëª…
        data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        min_days: ìµœì†Œ í•„ìš” ë°ì´í„° ì¼ìˆ˜ (ê¸°ë³¸ê°’: 200ì¼)
        recent_days: ìµœê·¼ ë°ì´í„° ì¶”ì¶œ ì¼ìˆ˜ (ê¸°ë³¸ê°’: 200ì¼)
        
    Returns:
        tuple: (ì‹¬ë³¼, ë°ì´í„°í”„ë ˆì„, ìµœê·¼ ë°ì´í„°) ë˜ëŠ” ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ (None, None, None)
    """
    try:
        file_path = os.path.join(data_dir, file)
        
        # Windows ì˜ˆì•½ íŒŒì¼ëª… ì²˜ë¦¬ - íŒŒì¼ëª…ì—ì„œ ì›ë˜ í‹°ì»¤ ì¶”ì¶œ
        symbol = extract_ticker_from_filename(file)
        
        # ê°œë³„ íŒŒì¼ ë¡œë“œ
        df = pd.read_csv(file_path)
        
        # ì»¬ëŸ¼ëª… ì†Œë¬¸ìë¡œ ë³€í™˜
        df.columns = [col.lower() for col in df.columns]
        
        # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
        if 'date' in df.columns:
            df['date'] = pd.to_datetime(df['date'], utc=True)
            df = df.sort_values('date')
        else:
            return None, None, None
            
        # ìµœì†Œ ë°ì´í„° ê¸¸ì´ í™•ì¸
        if len(df) < min_days:
            return None, None, None
        
        # ìµœê·¼ ë°ì´í„° ì¶”ì¶œ
        recent_data = df.iloc[-recent_days:].copy()
        
        return symbol, df, recent_data
        
    except Exception as e:
        print(f"âŒ {file} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return None, None, None

# Windows íŒŒì¼ëª… ì•ˆì „ì„± í™•ë³´ í•¨ìˆ˜
def safe_filename(filename):
    """Windowsì—ì„œ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ìë¥¼ ì œê±°í•˜ì—¬ ì•ˆì „í•œ íŒŒì¼ëª…ì„ ë§Œë“œëŠ” í•¨ìˆ˜
    
    Args:
        filename: ì›ë³¸ íŒŒì¼ëª…
        
    Returns:
        str: ì•ˆì „í•œ íŒŒì¼ëª…
    """
    # Windowsì—ì„œ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì: < > : \\ / | ? *
    invalid_chars = r'[<>:\\\/|?*"]'
    safe_name = re.sub(invalid_chars, '_', filename)
    
    # Windows ì˜ˆì•½ íŒŒì¼ëª… ì²˜ë¦¬
    reserved_names = [
        'CON', 'PRN', 'AUX', 'NUL',
        'COM1', 'COM2', 'COM3', 'COM4', 'COM5', 'COM6', 'COM7', 'COM8', 'COM9',
        'LPT1', 'LPT2', 'LPT3', 'LPT4', 'LPT5', 'LPT6', 'LPT7', 'LPT8', 'LPT9'
    ]
    
    name_without_ext = os.path.splitext(safe_name)[0]
    extension = os.path.splitext(safe_name)[1]
    
    if name_without_ext.upper() in reserved_names:
        safe_name = name_without_ext + '_file' + extension
    
    return safe_name

# ATR(Average True Range) ê³„ì‚° í•¨ìˆ˜
def calculate_atr(df, window=10):
    """ATR(Average True Range)ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        df: ê°€ê²© ë°ì´í„°ê°€ í¬í•¨ëœ DataFrame (high, low, close ì»¬ëŸ¼ í•„ìš”)
        window: ATR ê³„ì‚° ê¸°ê°„ (ê¸°ë³¸ê°’: 10ì¼)
        
    Returns:
        pandas.Series: ATR ê°’ ì‹œë¦¬ì¦ˆ
    """
    try:
        # í•„ìš”í•œ ì»¬ëŸ¼ í™•ì¸
        required_cols = ['high', 'low', 'close']
        for col in required_cols:
            if col not in df.columns:
                print(f"âš ï¸ ATR ê³„ì‚°ì— í•„ìš”í•œ '{col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return pd.Series(index=df.index)
        
        # ë°ì´í„° ë³µì‚¬
        df = df.copy()
        
        # True Range ê³„ì‚°
        df['prev_close'] = df['close'].shift(1)
        df['tr1'] = abs(df['high'] - df['low'])
        df['tr2'] = abs(df['high'] - df['prev_close'])
        df['tr3'] = abs(df['low'] - df['prev_close'])
        df['true_range'] = df[['tr1', 'tr2', 'tr3']].max(axis=1)
        
        # ATR ê³„ì‚° (ë‹¨ìˆœ ì´ë™í‰ê·  ì‚¬ìš©)
        df['atr'] = df['true_range'].rolling(window=window).mean()
        
        return df['atr']
    except Exception as e:
        print(f"âŒ ATR ê³„ì‚° ì˜¤ë¥˜: {e}")
        return pd.Series(index=df.index)

# RSI(Relative Strength Index) ê³„ì‚° í•¨ìˆ˜
def calculate_rsi(df, window=14):
    """RSI(Relative Strength Index)ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        df: ê°€ê²© ë°ì´í„°ê°€ í¬í•¨ëœ DataFrame (close ì»¬ëŸ¼ í•„ìš”)
        window: RSI ê³„ì‚° ê¸°ê°„ (ê¸°ë³¸ê°’: 14ì¼)
        
    Returns:
        pandas.Series: RSI ê°’ ì‹œë¦¬ì¦ˆ (0-100 ì‚¬ì´)
    """
    try:
        # í•„ìš”í•œ ì»¬ëŸ¼ í™•ì¸
        if 'close' not in df.columns:
            print(f"âš ï¸ RSI ê³„ì‚°ì— í•„ìš”í•œ 'close' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return pd.Series(index=df.index)
        
        # ì¢…ê°€ ë³€í™”ëŸ‰ ê³„ì‚°
        delta = df['close'].diff()
        
        # ìƒìŠ¹/í•˜ë½ êµ¬ë¶„
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)
        
        # í‰ê·  ìƒìŠ¹/í•˜ë½ ê³„ì‚°
        avg_gain = gain.rolling(window=window).mean()
        avg_loss = loss.rolling(window=window).mean()
        
        # ìƒëŒ€ì  ê°•ë„(RS) ê³„ì‚°
        rs = avg_gain / avg_loss.where(avg_loss != 0, 1)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
        
        # RSI ê³„ì‚°
        rsi = 100 - (100 / (1 + rs))
        
        return rsi
    except Exception as e:
        print(f"âŒ RSI ê³„ì‚° ì˜¤ë¥˜: {e}")
        return pd.Series(index=df.index)

# ADX(Average Directional Index) ê³„ì‚° í•¨ìˆ˜
def calculate_adx(df, window=14):
    """ADX(Average Directional Index)ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        df: ê°€ê²© ë°ì´í„°ê°€ í¬í•¨ëœ DataFrame (high, low, close ì»¬ëŸ¼ í•„ìš”)
        window: ADX ê³„ì‚° ê¸°ê°„ (ê¸°ë³¸ê°’: 14ì¼)
        
    Returns:
        pandas.Series: ADX ê°’ ì‹œë¦¬ì¦ˆ
    """
    try:
        # í•„ìš”í•œ ì»¬ëŸ¼ í™•ì¸
        required_cols = ['high', 'low', 'close']
        for col in required_cols:
            if col not in df.columns:
                print(f"âš ï¸ ADX ê³„ì‚°ì— í•„ìš”í•œ '{col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return pd.Series(index=df.index)
        
        # ë°ì´í„° ë³µì‚¬
        df = df.copy()
        
        # ê°€ê²© ë³€í™” ê³„ì‚°
        df['prev_high'] = df['high'].shift(1)
        df['prev_low'] = df['low'].shift(1)
        df['prev_close'] = df['close'].shift(1)
        
        # +DM, -DM ê³„ì‚°
        df['up_move'] = df['high'] - df['prev_high']
        df['down_move'] = df['prev_low'] - df['low']
        
        # +DM ì¡°ê±´: ìƒìŠ¹í­ì´ í•˜ë½í­ë³´ë‹¤ í¬ê³ , ìƒìŠ¹í­ì´ ì–‘ìˆ˜ì¼ ë•Œ
        df['+dm'] = np.where(
            (df['up_move'] > df['down_move']) & (df['up_move'] > 0),
            df['up_move'],
            0
        )
        
        # -DM ì¡°ê±´: í•˜ë½í­ì´ ìƒìŠ¹í­ë³´ë‹¤ í¬ê³ , í•˜ë½í­ì´ ì–‘ìˆ˜ì¼ ë•Œ
        df['-dm'] = np.where(
            (df['down_move'] > df['up_move']) & (df['down_move'] > 0),
            df['down_move'],
            0
        )
        
        # True Range ê³„ì‚°
        df['tr1'] = abs(df['high'] - df['low'])
        df['tr2'] = abs(df['high'] - df['prev_close'])
        df['tr3'] = abs(df['low'] - df['prev_close'])
        df['tr'] = df[['tr1', 'tr2', 'tr3']].max(axis=1)
        
        # ì´ˆê¸° í‰ê· ê°’ ê³„ì‚°
        df['+dm_avg'] = df['+dm'].rolling(window=window).mean()
        df['-dm_avg'] = df['-dm'].rolling(window=window).mean()
        df['tr_avg'] = df['tr'].rolling(window=window).mean()
        
        # +DI, -DI ê³„ì‚°
        df['+di'] = 100 * df['+dm_avg'] / df['tr_avg']
        df['-di'] = 100 * df['-dm_avg'] / df['tr_avg']
        
        # DX ê³„ì‚°
        df['dx'] = 100 * abs(df['+di'] - df['-di']) / (df['+di'] + df['-di'])
        
        # ADX ê³„ì‚° (DXì˜ ì´ë™í‰ê· )
        df['adx'] = df['dx'].rolling(window=window).mean()
        
        return df['adx']
    except Exception as e:
        print(f"âŒ ADX ê³„ì‚° ì˜¤ë¥˜: {e}")
        return pd.Series(index=df.index)

# ì—­ì‚¬ì  ë³€ë™ì„± ê³„ì‚° í•¨ìˆ˜
def calculate_historical_volatility(df, window=60, annualize=True):
    """ì—­ì‚¬ì  ë³€ë™ì„±ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        df: ê°€ê²© ë°ì´í„°ê°€ í¬í•¨ëœ DataFrame (close ì»¬ëŸ¼ í•„ìš”)
        window: ë³€ë™ì„± ê³„ì‚° ê¸°ê°„ (ê¸°ë³¸ê°’: 60ì¼)
        annualize: ì—°ê°„í™” ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        
    Returns:
        float: ë³€ë™ì„± ê°’ (ë°±ë¶„ìœ¨)
    """
    try:
        # í•„ìš”í•œ ì»¬ëŸ¼ í™•ì¸
        if 'close' not in df.columns:
            print(f"âš ï¸ ë³€ë™ì„± ê³„ì‚°ì— í•„ìš”í•œ 'close' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return pd.Series(index=df.index)
        
        # ë¡œê·¸ ìˆ˜ìµë¥  ê³„ì‚°
        df = df.copy()
        df['log_return'] = np.log(df['close'] / df['close'].shift(1))
        
        # ë³€ë™ì„± ê³„ì‚° (í‘œì¤€í¸ì°¨)
        volatility = df['log_return'].rolling(window=window).std()
        
        # ì—°ê°„í™” (252 ê±°ë˜ì¼ ê¸°ì¤€)
        if annualize:
            volatility = volatility * np.sqrt(252) * 100
        else:
            volatility = volatility * 100
        
        return volatility
    except Exception as e:
        print(f"âŒ ë³€ë™ì„± ê³„ì‚° ì˜¤ë¥˜: {e}")
        return pd.Series(index=df.index)

# S&P 500 ì¡°ê±´ í™•ì¸ í•¨ìˆ˜
def check_sp500_condition(data_dir, ma_days=100):
    """SPY ì¢…ê°€ê°€ ì§€ì •ëœ ì´ë™í‰ê· ì„  ìœ„ì— ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        ma_days: ì´ë™í‰ê·  ê¸°ê°„ (ê¸°ë³¸ê°’: 100ì¼)
        
    Returns:
        bool: SPY ì¡°ê±´ ì¶©ì¡± ì—¬ë¶€
    """
    try:
        # SPY ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        spy_file = os.path.join(data_dir, 'SPY.csv')
        if not os.path.exists(spy_file):
            print("âš ï¸ SPY ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False  # SPY ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì§„í–‰í•˜ì§€ ì•ŠìŒ
        
        # SPY ë°ì´í„° ë¡œë“œ
        spy_df = pd.read_csv(spy_file)
        spy_df.columns = [col.lower() for col in spy_df.columns]
        
        if 'date' in spy_df.columns:
            spy_df['date'] = pd.to_datetime(spy_df['date'], utc=True)
            spy_df = spy_df.sort_values('date')
        else:
            print("âš ï¸ SPY ë°ì´í„°ì— ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False  # ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì§„í–‰í•˜ì§€ ì•ŠìŒ
        
        # ìµœì†Œ ë°ì´í„° ê¸¸ì´ í™•ì¸
        if len(spy_df) < ma_days:
            print("âš ï¸ SPY ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return False  # ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ì§„í–‰í•˜ì§€ ì•ŠìŒ
        
        # ì´ë™í‰ê·  ê³„ì‚°
        spy_df[f'ma{ma_days}'] = spy_df['close'].rolling(window=ma_days).mean()
        
        # ìµœì‹  ë°ì´í„° í™•ì¸
        latest_spy = spy_df.iloc[-1]
        
        # ì¡°ê±´: SPY ì¢…ê°€ê°€ ì´ë™í‰ê· ì„  ìœ„ì— ìˆìŒ
        spy_condition = latest_spy['close'] > latest_spy[f'ma{ma_days}']
        
        if not spy_condition:
            print(f"âš ï¸ SPY ì¢…ê°€ê°€ {ma_days}ì¼ ì´ë™í‰ê· ì„  ì•„ë˜ì— ìˆìŠµë‹ˆë‹¤.")
            return False  # SPY ì¡°ê±´ì„ ì¶©ì¡±í•˜ì§€ ì•Šìœ¼ë©´ ì§„í–‰í•˜ì§€ ì•ŠìŒ
        
        return True
        
    except Exception as e:
        print(f"âŒ SPY ì¡°ê±´ í™•ì¸ ì˜¤ë¥˜: {e}")
        return False  # ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì§„í–‰í•˜ì§€ ì•ŠìŒ