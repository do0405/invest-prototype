#!/usr/bin/env python3
"""
ê³ ê¸‰ IPO ë°ì´í„° ìˆ˜ì§‘ê¸° - ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ IPO ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ëª¨ë“ˆí™”ëœ ë°ì´í„° ì†ŒìŠ¤ ì§€ì›
- ê³¼ê±° ë° ì˜ˆì •ëœ IPO ë°ì´í„° ëª¨ë‘ ìˆ˜ì§‘
- CSV ë° JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥
- ì¬ì‹œë„ ë¡œì§ ë° ì˜¤ë¥˜ ì²˜ë¦¬
"""

import logging
import os
import json
import time
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import pandas as pd
import requests
from pathlib import Path

# SEC Edgar ë°ì´í„° ì†ŒìŠ¤ë§Œ ì‚¬ìš©
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data_sources.sec_edgar_source import SecEdgarSource

# ë¡œê¹… ì„¤ì • (ì¤‘ë³µ ë°©ì§€)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    force=True  # ê¸°ì¡´ ì„¤ì •ì„ ë®ì–´ì”€
)
logger = logging.getLogger(__name__)

class RealIPODataCollector:
    """ì‹¤ì œ IPO ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, data_dir: str = None):
        # ê¸°ë³¸ ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì •
        if data_dir is None:
            # configì—ì„œ DATA_DIR ê°€ì ¸ì˜¤ê¸°
            try:
                sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
                from config import DATA_DIR
                data_dir = os.path.join(DATA_DIR, 'IPO')
            except ImportError:
                data_dir = "../../data/IPO"
        
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # SEC Edgar ë°ì´í„° ì†ŒìŠ¤ë§Œ ì‚¬ìš©
        self.sec_edgar_source = SecEdgarSource()
        
        logger.info(f"IPO ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ: {self.data_dir}")
    
    # ê¸°ì¡´ ê°œë³„ ë©”ì„œë“œë“¤ì€ ëª¨ë“ˆí™”ëœ ë°ì´í„° ì†ŒìŠ¤ë¡œ ì´ë™ë¨
    
    def _clean_and_deduplicate(self, ipos: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """IPO ë°ì´í„° ì •ë¦¬ ë° ì¤‘ë³µ ì œê±°"""
        if not ipos:
            return []
        
        # ì‹¬ë³¼ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±° (ìš°ì„ ìˆœìœ„: finance_calendars > investpy)
        seen_symbols = set()
        cleaned_ipos = []
        
        # finance_calendars ë°ì´í„° ìš°ì„  ì²˜ë¦¬
        for ipo in ipos:
            symbol = ipo.get('symbol', 'N/A')
            if symbol != 'N/A' and symbol not in seen_symbols:
                seen_symbols.add(symbol)
                cleaned_ipos.append(ipo)
            elif symbol == 'N/A':
                # ì‹¬ë³¼ì´ ì—†ëŠ” ê²½ìš° íšŒì‚¬ëª…ìœ¼ë¡œ ì¤‘ë³µ ì²´í¬
                company_name = ipo.get('company_name', 'N/A')
                if company_name not in [c.get('company_name') for c in cleaned_ipos]:
                    cleaned_ipos.append(ipo)
        
        logger.info(f"ì¤‘ë³µ ì œê±° í›„ {len(cleaned_ipos)}ê°œ IPO ë°ì´í„°")
        return cleaned_ipos
    
    def _save_to_files(self, data: List[Dict[str, Any]], file_prefix: str) -> Dict[str, str]:
        """ë°ì´í„°ë¥¼ CSVì™€ JSON íŒŒì¼ë¡œ ì €ì¥"""
        if not data:
            logger.warning(f"{file_prefix} ë°ì´í„°ê°€ ë¹„ì–´ìˆì–´ íŒŒì¼ì„ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return {}
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ íŒŒì¼ëª… ì‚¬ìš©
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        # CSV íŒŒì¼ ì €ì¥
        csv_filename = f"{file_prefix}_{timestamp}.csv"
        csv_path = self.data_dir / csv_filename
        
        df = pd.DataFrame(data)
        df.to_csv(csv_path, index=False, encoding='utf-8')
        logger.info(f"CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {csv_path} ({len(data)}ê°œ IPO)")
        
        # JSON íŒŒì¼ ì €ì¥
        json_filename = f"{file_prefix}_{timestamp}.json"
        json_path = self.data_dir / json_filename
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        logger.info(f"JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {json_path} ({len(data)}ê°œ IPO)")
        
        return {
            'csv': str(csv_path),
            'json': str(json_path)
        }
    
    def collect_all_ipo_data(self) -> Dict[str, Any]:
        """SEC Edgarì—ì„œ IPO ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥"""
        logger.info("SEC Edgar IPO ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        
        recent_ipos = []
        upcoming_ipos = []
        
        try:
            # SEC Edgar ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            if self.sec_edgar_source.is_available():
                logger.info("SEC Edgarì—ì„œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
                
                # ìµœê·¼ IPO ë°ì´í„° ìˆ˜ì§‘
                recent_data = self.sec_edgar_source.get_recent_ipos(months_back=6)
                if recent_data:
                    recent_ipos.extend(recent_data)
                    logger.info(f"SEC Edgar: ìµœê·¼ IPO {len(recent_data)}ê°œ ìˆ˜ì§‘")
                
                # ì˜ˆì •ëœ IPO ë°ì´í„° ìˆ˜ì§‘
                upcoming_data = self.sec_edgar_source.get_upcoming_ipos(months_ahead=3)
                if upcoming_data:
                    upcoming_ipos.extend(upcoming_data)
                    logger.info(f"SEC Edgar: ì˜ˆì • IPO {len(upcoming_data)}ê°œ ìˆ˜ì§‘")
                    
            else:
                logger.warning("SEC Edgar APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            logger.error(f"SEC Edgar ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        # ë°ì´í„° ì •ë¦¬ ë° ì¤‘ë³µ ì œê±°
        recent_ipos = self._clean_and_deduplicate(recent_ipos)
        upcoming_ipos = self._clean_and_deduplicate(upcoming_ipos)
        
        # íŒŒì¼ ì €ì¥
        recent_files = self._save_to_files(recent_ipos, 'recent_ipos')
        upcoming_files = self._save_to_files(upcoming_ipos, 'upcoming_ipos')
        
        logger.info("SEC Edgar IPO ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥ ì™„ë£Œ")
        
        return {
            'recent_ipos': recent_ipos,
            'upcoming_ipos': upcoming_ipos,
            'files': {
                'recent': recent_files,
                'upcoming': upcoming_files
            },
            'source': 'sec_edgar'
        }

    def get_recent_ipos(self, days_back: int = 365) -> pd.DataFrame:
        """ìµœê·¼ IPO ë°ì´í„°ë¥¼ íŒŒì¼ì—ì„œ ë¡œë“œ"""
        # íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ íŒŒì¼ë“¤ì„ ìš°ì„  í™•ì¸
        csv_files = sorted(self.data_dir.glob('recent_ipos_*.csv'))
        if not csv_files:
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì—†ëŠ” íŒŒì¼ì„ í™•ì¸
            recent_ipos_file = self.data_dir / 'recent_ipos.csv'
            if recent_ipos_file.exists():
                csv_files = [recent_ipos_file]
        
        if not csv_files:
            return pd.DataFrame()

        df_list = []
        for file in csv_files:
            df = pd.read_csv(file)
            df.columns = [c.lower() for c in df.columns]
            if 'ticker' in df.columns and 'symbol' not in df.columns:
                df.rename(columns={'ticker': 'symbol'}, inplace=True)
            if 'date' in df.columns and 'ipo_date' not in df.columns:
                df.rename(columns={'date': 'ipo_date'}, inplace=True)
            if 'price_range' in df.columns and 'ipo_price' not in df.columns:
                df['ipo_price'] = (
                    df['price_range']
                    .astype(str)
                    .str.replace('$', '')
                    .str.split('-')
                    .str[0]
                    .str.replace(',', '')
                )
            df_list.append(df)

        df_all = pd.concat(df_list, ignore_index=True)
        if 'ipo_date' in df_all.columns:
            df_all['ipo_date'] = pd.to_datetime(df_all['ipo_date'], errors='coerce', utc=True)
            cutoff = pd.Timestamp.utcnow() - pd.Timedelta(days=days_back)
            df_all = df_all[df_all['ipo_date'] >= cutoff]
        return df_all

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    collector = RealIPODataCollector()
    
    try:
        results = collector.collect_all_ipo_data()
        
        print("\n=== ìˆ˜ì§‘ ê²°ê³¼ ===")
        print(f"ê³¼ê±° IPO ë°ì´í„°: {len(results['recent_ipos'])}ê°œ")
        print(f"ì˜ˆì •ëœ IPO ë°ì´í„°: {len(results['upcoming_ipos'])}ê°œ")
        
        # ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
        if results['recent_ipos']:
            print("\n=== ìµœê·¼ IPO ìƒ˜í”Œ ===")
            for ipo in results['recent_ipos'][:3]:
                symbol = ipo.get('symbol', 'N/A')
                company = ipo.get('company_name', 'N/A')
                date = ipo.get('ipo_date', 'N/A')
                print(f"- {symbol}: {company} ({date})")
        
        if results['upcoming_ipos']:
            print("\n=== ì˜ˆì •ëœ IPO ìƒ˜í”Œ ===")
            for ipo in results['upcoming_ipos'][:3]:
                symbol = ipo.get('symbol', 'N/A')
                company = ipo.get('company_name', 'N/A')
                date = ipo.get('expected_ipo_date', 'N/A')
                print(f"- {symbol}: {company} ({date})")
        
            
    except Exception as e:
        logger.error(f"IPO ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise


if __name__ == "__main__":
    try:
        collector = RealIPODataCollector()
        results = collector.collect_all_ipo_data()
        
        print(f"\nâœ… IPO ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
        print(f"ğŸ“Š ìµœê·¼ IPO: {len(results['recent_ipos'])}ê°œ")
        print(f"ğŸ“… ì˜ˆì •ëœ IPO: {len(results['upcoming_ipos'])}ê°œ")
        
        # ì €ì¥ëœ íŒŒì¼ ì •ë³´
        print("\n=== ì €ì¥ëœ íŒŒì¼ ===")
        files = results['files']
        if files.get('recent'):
            print(f"- recent_csv: {files['recent']['csv']}")
            print(f"- recent_json: {files['recent']['json']}")
        if files.get('upcoming'):
            print(f"- upcoming_csv: {files['upcoming']['csv']}")
            print(f"- upcoming_json: {files['upcoming']['json']}")
            
    except Exception as e:
        logger.error(f"IPO ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise
