# -*- coding: utf-8 -*-
# ìƒˆë¡œ ì¶”ê°€ëœ í‹°ì»¤ ì¶”ì  ëª¨ë“ˆ

import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import csv

import sys
sys.path.append("..")
from config import MARKMINERVINI_RESULTS_DIR, US_WITH_RS_PATH

# ìƒˆë¡œ ì¶”ê°€ëœ í‹°ì»¤ë¥¼ ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
NEW_TICKERS_PATH = os.path.join(MARKMINERVINI_RESULTS_DIR, 'new_tickers.csv')
# ì´ì „ us_with_rs.csv íŒŒì¼ ë°±ì—… ê²½ë¡œ
PREVIOUS_US_WITH_RS_PATH = os.path.join(MARKMINERVINI_RESULTS_DIR, 'previous_us_with_rs.csv')

def track_new_tickers(advanced_financial_results_path):
    """
    us_with_rs.csv íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ìƒˆë¡œ ì¶”ê°€ëœ í‹°ì»¤ë¥¼ ì¶”ì í•˜ê³  ê´€ë¦¬í•©ë‹ˆë‹¤.
    ìƒˆë¡œ ì¶”ê°€ëœ í‹°ì»¤ëŠ” new_tickers.csv íŒŒì¼ì— ì €ì¥ë˜ë©°, 2ì£¼ ì´ìƒ ì§€ë‚œ ë°ì´í„°ëŠ” ìë™ìœ¼ë¡œ ì‚­ì œë©ë‹ˆë‹¤.
    
    Args:
        advanced_financial_results_path (str): ê³ ê¸‰ ì¬ë¬´ì œí‘œ ë¶„ì„ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
    """
    print("\nğŸ” ìƒˆë¡œ ì¶”ê°€ëœ í‹°ì»¤ë¥¼ ì¶”ì í•©ë‹ˆë‹¤...")
    
    # í˜„ì¬ ë‚ ì§œ
    today = datetime.now().date()
    
    # us_with_rs.csv íŒŒì¼ ë¡œë“œ
    try:
        current_us_with_rs = pd.read_csv(US_WITH_RS_PATH)
        
        # symbol ì»¬ëŸ¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if 'symbol' not in current_us_with_rs.columns:
            print(f"ê²½ê³ : {US_WITH_RS_PATH} íŒŒì¼ì— symbol ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
                
    except FileNotFoundError:
        print(f"ê²½ê³ : {US_WITH_RS_PATH} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    except Exception as e:
        print(f"ì˜¤ë¥˜: us_with_rs.csv íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return
    
    # ê³ ê¸‰ ì¬ë¬´ì œí‘œ ë¶„ì„ ê²°ê³¼ íŒŒì¼ ë¡œë“œ
    try:
        financial_results = pd.read_csv(advanced_financial_results_path)
    except FileNotFoundError:
        print(f"ê²½ê³ : {advanced_financial_results_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    except Exception as e:
        print(f"ì˜¤ë¥˜: ê³ ê¸‰ ì¬ë¬´ì œí‘œ ë¶„ì„ ê²°ê³¼ íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return
    
    # ì´ì „ us_with_rs.csv íŒŒì¼ ë¡œë“œ ë˜ëŠ” ìƒì„±
    if os.path.exists(PREVIOUS_US_WITH_RS_PATH):
        try:
            previous_us_with_rs = pd.read_csv(PREVIOUS_US_WITH_RS_PATH)
            
            # symbol ì»¬ëŸ¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            if 'symbol' not in previous_us_with_rs.columns:
                print(f"ê²½ê³ : {PREVIOUS_US_WITH_RS_PATH} íŒŒì¼ì— symbol ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                previous_us_with_rs = pd.DataFrame()  # ë¹ˆ DataFrameìœ¼ë¡œ ì„¤ì •
                    
            previous_symbols = set(previous_us_with_rs['symbol'].tolist())
        except Exception as e:
            print(f"ê²½ê³ : ì´ì „ us_with_rs.csv íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            previous_symbols = set()
    else:
        previous_symbols = set()
    
    # í˜„ì¬ us_with_rs.csvì˜ ì‹¬ë³¼ ëª©ë¡ ì¶”ì¶œ
    current_symbols = set(current_us_with_rs['symbol'].tolist())
    
    # ìƒˆë¡œ ì¶”ê°€ëœ í‹°ì»¤ ì°¾ê¸° (í˜„ì¬ - ì´ì „)
    new_symbols = current_symbols - previous_symbols
    
    # ìƒˆë¡œ ì¶”ê°€ëœ í‹°ì»¤ íŒŒì¼ ë¡œë“œ ë˜ëŠ” ìƒì„±
    if os.path.exists(NEW_TICKERS_PATH):
        try:
            new_tickers_df = pd.read_csv(NEW_TICKERS_PATH)
        except Exception as e:
            print(f"ì˜¤ë¥˜: ìƒˆë¡œ ì¶”ê°€ëœ í‹°ì»¤ íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            new_tickers_df = pd.DataFrame(columns=['symbol', 'fin_met_count', 'rs_score', 'met_count', 'total_met_count', 'added_date'])
    else:
        new_tickers_df = pd.DataFrame(columns=['symbol', 'fin_met_count', 'rs_score', 'met_count', 'total_met_count', 'added_date'])
    
    # ìƒˆë¡œ ì¶”ê°€ëœ í‹°ì»¤ê°€ ìˆìœ¼ë©´ ì²˜ë¦¬
    if new_symbols:
        print(f"ìƒˆë¡œ ì¶”ê°€ëœ í‹°ì»¤ {len(new_symbols)}ê°œë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
        
        # ìƒˆë¡œ ì¶”ê°€ëœ í‹°ì»¤ ì •ë³´ ì¶”ì¶œ
        new_tickers_info = []
        for symbol in new_symbols:
            # us_with_rs.csvì—ì„œ RS ì ìˆ˜ ê°€ì ¸ì˜¤ê¸°
            us_data = current_us_with_rs[current_us_with_rs['symbol'] == symbol]
            if us_data.empty:
                continue
                
            rs_score = us_data.iloc[0].get('rs_score', 0)
            
            # ì¬ë¬´ì œí‘œ ë¶„ì„ ê²°ê³¼ì—ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            fin_data = financial_results[financial_results['symbol'] == symbol]
            fin_met_count = 0
            met_count = 0
            total_met_count = 0
            
            if not fin_data.empty:
                fin_met_count = fin_data.iloc[0].get('fin_met_count', 0)
                
                # ê¸°ìˆ ì  ì§€í‘œ ì¶©ì¡± ê°œìˆ˜ (8ê°œ ì¤‘)
                # ë¨¼ì € us_with_rs.csvì—ì„œ met_count ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤
                us_data_met_count = us_data.iloc[0].get('met_count', 0)
                if us_data_met_count > 0:
                    met_count = us_data_met_count
                else:
                    # tech_ ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ëŒ€ì²´ ë°©ë²•ìœ¼ë¡œ ì‹œë„
                    tech_columns = [col for col in fin_data.columns if col.startswith('tech_')]
                    if tech_columns:
                        met_count = fin_data.iloc[0][tech_columns].sum()
                    else:
                        # integrated_results.csv íŒŒì¼ì—ì„œ met_count ê°’ì„ ê°€ì ¸ì˜¤ëŠ” ë¡œì§ ì¶”ê°€
                        integrated_results_path = os.path.join(MARKMINERVINI_RESULTS_DIR, 'integrated_results.csv')
                        if os.path.exists(integrated_results_path):
                            try:
                                integrated_df = pd.read_csv(integrated_results_path)
                                integrated_data = integrated_df[integrated_df['symbol'] == symbol]
                                if not integrated_data.empty:
                                    met_count = integrated_data.iloc[0].get('met_count', 0)
                            except Exception as e:
                                print(f"í†µí•© ê²°ê³¼ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
                
                # ì´ ì¶©ì¡± ì§€í‘œ ê°œìˆ˜
                total_met_count = fin_met_count + met_count
            
            # ìƒˆë¡œìš´ í‹°ì»¤ ì •ë³´ ì¶”ê°€
            new_tickers_info.append({
                'symbol': symbol,
                'fin_met_count': fin_met_count,
                'rs_score': rs_score,
                'met_count': met_count,
                'total_met_count': total_met_count,
                'added_date': today.strftime('%Y-%m-%d')
            })
        
        # ìƒˆë¡œìš´ í‹°ì»¤ ì •ë³´ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        new_tickers_df_to_add = pd.DataFrame(new_tickers_info)
        
        # ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆë¡œìš´ ë°ì´í„° ë³‘í•© (ë¹ˆ DataFrame ì²´í¬)
        if not new_tickers_df_to_add.empty:
            if new_tickers_df.empty:
                new_tickers_df = new_tickers_df_to_add.copy()
            else:
                new_tickers_df = pd.concat([new_tickers_df, new_tickers_df_to_add], ignore_index=True)
    else:
        print("ìƒˆë¡œ ì¶”ê°€ëœ í‹°ì»¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
    # í˜„ì¬ us_with_rs.csvë¥¼ ì´ì „ íŒŒì¼ë¡œ ë°±ì—…
    try:
        # ì´ì „ ê²°ê³¼ ë°±ì—…
        current_us_with_rs.to_csv(PREVIOUS_US_WITH_RS_PATH, index=False)
        # JSON íŒŒì¼ ìƒì„± ì¶”ê°€
        json_path = PREVIOUS_US_WITH_RS_PATH.replace('.csv', '.json')
        current_us_with_rs.to_json(json_path, orient='records', indent=2, force_ascii=False)
        
    except Exception as e:
        print(f"ê²½ê³ : í˜„ì¬ us_with_rs.csv íŒŒì¼ì„ ë°±ì—…í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    
    # 2ì£¼ ì´ìƒ ì§€ë‚œ ë°ì´í„° ì‚­ì œ
    two_weeks_ago = today - timedelta(days=14)
    new_tickers_df['added_date'] = pd.to_datetime(new_tickers_df['added_date'], utc=True).dt.date
    new_tickers_df = new_tickers_df[new_tickers_df['added_date'] > two_weeks_ago]
    
    # ì¶”ê°€ëœ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (ìµœì‹  ë°ì´í„°ê°€ ìœ„ë¡œ)
    new_tickers_df = new_tickers_df.sort_values(by='added_date', ascending=False)
    
    # ê²°ê³¼ ì €ì¥
    try:
        new_tickers_df.to_csv(NEW_TICKERS_PATH, index=False)
        json_path = NEW_TICKERS_PATH.replace('.csv', '.json')
        new_tickers_df.to_json(json_path, orient='records', indent=2, force_ascii=False)
        print(f"ìƒˆë¡œ ì¶”ê°€ëœ í‹°ì»¤ ì •ë³´ë¥¼ {NEW_TICKERS_PATH}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        print(f"í˜„ì¬ ì¶”ì  ì¤‘ì¸ í‹°ì»¤ ìˆ˜: {len(new_tickers_df)}")
        
        # ìƒˆë¡œ ì¶”ê°€ëœ í‹°ì»¤ì— ëŒ€í•´ í†µí•© ìŠ¤í¬ë¦¬ë„ˆ ì‹¤í–‰ (íŒ¨í„´ ê°ì§€ í¬í•¨)
        if new_symbols and len(new_symbols) > 0:
            try:
                print("\nğŸ” ìƒˆë¡œ ì¶”ê°€ëœ í‹°ì»¤ì— ëŒ€í•œ í†µí•© íŒ¨í„´ ê°ì§€ ìŠ¤í¬ë¦¬ë„ˆ ì‹¤í–‰ ì¤‘...")
                from .integrated_screener import run_integrated_screening
                
                # ìƒˆë¡œ ì¶”ê°€ëœ ì‹¬ë³¼ë§Œ íŒ¨í„´ ê°ì§€
                new_symbols_list = list(new_symbols)
                if new_symbols_list:
                    pattern_results = run_integrated_screening(max_symbols=len(new_symbols_list))
                    print(f"âœ… ìƒˆ í‹°ì»¤ íŒ¨í„´ ê°ì§€ ì™„ë£Œ: {len(pattern_results)}ê°œ ì‹¬ë³¼ ì²˜ë¦¬")
                else:
                    print("âš ï¸ íŒ¨í„´ ê°ì§€í•  ìƒˆ ì‹¬ë³¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"âš ï¸ ìƒˆ í‹°ì»¤ í†µí•© íŒ¨í„´ ê°ì§€ ì˜¤ë¥˜: {e}")
                
    except Exception as e:
        print(f"ì˜¤ë¥˜: ìƒˆë¡œ ì¶”ê°€ëœ í‹°ì»¤ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
