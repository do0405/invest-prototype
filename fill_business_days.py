# -*- coding: utf-8 -*-
# ì˜ì—…ì¼ ë°ì´í„° ì±„ìš°ê¸° ëª¨ë“ˆ (yfinance ì‚¬ìš© ë²„ì „)

import os
import pandas as pd
import numpy as np
import glob
import time
import yfinance as yf
from datetime import datetime, timedelta
from pytz import timezone
from concurrent.futures import ThreadPoolExecutor

# ì„¤ì • ì„í¬íŠ¸
from config import DATA_DIR, DATA_US_DIR

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì„í¬íŠ¸
from utils import ensure_dir, safe_filename

def fill_missing_business_days_with_yfinance(csv_file, output_file=None):
    """
    CSV íŒŒì¼ì—ì„œ ë¹ ì§„ ì˜ì—…ì¼ì„ yfinanceì—ì„œ ì‹¤ì œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ì±„ìš°ëŠ” í•¨ìˆ˜
    
    Args:
        csv_file: ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ
        output_file: ì¶œë ¥ CSV íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: None, ì…ë ¥ íŒŒì¼ì„ ë®ì–´ì”€)
        
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    try:
        # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not os.path.exists(csv_file):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {csv_file}")
            return False
            
        # CSV íŒŒì¼ ë¡œë“œ
        df = pd.read_csv(csv_file)
        
        # ë‚ ì§œ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
        if 'date' not in df.columns:
            print(f"âŒ ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ìŒ: {csv_file}")
            return False
            
        # ë¹ˆ ë°ì´í„°í”„ë ˆì„ì¸ ê²½ìš° (ìƒì¥ íì§€ ì¢…ëª©)
        if len(df) == 0:
            print(f"âš ï¸ ë¹ˆ ë°ì´í„°í”„ë ˆì„ (ìƒì¥ íì§€ ì¢…ëª©): {csv_file}")
            return False
            
        # ë‚ ì§œ ì»¬ëŸ¼ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        df['date'] = pd.to_datetime(df['date'], utc=True)
        
        # ì‹¬ë³¼ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
        symbol = None
        if 'symbol' in df.columns:
            symbol = df['symbol'].iloc[0]
        else:
            # íŒŒì¼ëª…ì—ì„œ ì‹¬ë³¼ ì¶”ì¶œ
            symbol = os.path.splitext(os.path.basename(csv_file))[0]
        
        # ë‚ ì§œë¡œ ì •ë ¬
        df = df.sort_values('date')
        
        # ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ ê°€ì ¸ì˜¤ê¸°
        start_date = df['date'].min().date()
        end_date = df['date'].max().date()
        today = datetime.now(timezone('UTC')).date()
        
        # ì˜ì—…ì¼ ë‚ ì§œ ë²”ìœ„ ìƒì„± (ì£¼ë§ ì œì™¸)
        business_days = pd.date_range(start=start_date, end=end_date, freq='B')
        
        # ê¸°ì¡´ ë°ì´í„°ì˜ ë‚ ì§œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµìš© ì§‘í•© ìƒì„±
        existing_dates = set(df['date'].dt.strftime('%Y-%m-%d'))
        
        # ëˆ„ë½ëœ ë‚ ì§œ ì°¾ê¸°
        missing_dates = []
        for date in business_days:
            date_str = date.strftime('%Y-%m-%d')
            if date_str not in existing_dates:
                missing_dates.append(date.date())
        
        if not missing_dates:
            print(f"âœ… ëˆ„ë½ëœ ì˜ì—…ì¼ ì—†ìŒ: {os.path.basename(csv_file)}")
            return True
        
        print(f"ğŸ” ëˆ„ë½ëœ ì˜ì—…ì¼ ë°œê²¬: {os.path.basename(csv_file)} ({len(missing_dates)}ê°œ)")
        
        # ëˆ„ë½ëœ ë‚ ì§œê°€ ìˆëŠ” ê²½ìš° yfinanceì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        # ì—°ì†ëœ ë‚ ì§œ ë²”ìœ„ë¡œ ë¬¶ê¸°
        date_ranges = []
        if missing_dates:
            current_range = [missing_dates[0]]
            for i in range(1, len(missing_dates)):
                if (missing_dates[i] - missing_dates[i-1]).days <= 5:  # 5ì¼ ì´ë‚´ë©´ ê°™ì€ ë²”ìœ„ë¡œ ê°„ì£¼
                    current_range.append(missing_dates[i])
                else:
                    date_ranges.append((current_range[0], current_range[-1]))
                    current_range = [missing_dates[i]]
            date_ranges.append((current_range[0], current_range[-1]))
        
        # ê° ë‚ ì§œ ë²”ìœ„ì— ëŒ€í•´ yfinanceì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        new_data_frames = []
        for start, end in date_ranges:
            # ì¢…ë£Œì¼ì€ ë‹¤ìŒ ë‚ ì§œë¡œ ì„¤ì • (yfinanceëŠ” ì¢…ë£Œì¼ì„ í¬í•¨í•˜ì§€ ì•ŠìŒ)
            end_plus_one = end + timedelta(days=1)
            
            # ì‹œë„ íšŸìˆ˜ ì„¤ì •
            max_retries = 3
            retry_count = 0
            success = False
            
            while retry_count < max_retries and not success:
                try:
                    print(f"[YF] ğŸ“Š ë°ì´í„° ìš”ì²­ ì¤‘: {symbol} ({start} ~ {end})")
                    ticker_obj = yf.Ticker(symbol)
                    new_df = ticker_obj.history(start=start, end=end_plus_one, interval="1d",
                                              auto_adjust=False, actions=False, timeout=10)
                    
                    if not new_df.empty:
                        new_df = new_df.rename_axis("date").reset_index()
                        new_df["symbol"] = symbol
                        new_data_frames.append(new_df)
                        print(f"[YF] âœ… ë°ì´í„° ìˆ˜ì‹  ì„±ê³µ: {symbol} ({start} ~ {end}, {len(new_df)} í–‰)")
                        success = True
                    else:
                        print(f"[YF] âš ï¸ ë¹ˆ ë°ì´í„° ë°˜í™˜ë¨: {symbol} ({start} ~ {end})")
                        retry_count += 1
                        time.sleep(2)
                except Exception as e:
                    print(f"[YF] âŒ ì˜¤ë¥˜ ë°œìƒ: {symbol} ({start} ~ {end}) - {str(e)[:100]}")
                    retry_count += 1
                    time.sleep(2)
        
        if not new_data_frames:
            print(f"âš ï¸ ëˆ„ë½ëœ ë‚ ì§œì— ëŒ€í•œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í•¨: {os.path.basename(csv_file)}")
            return False
        
        # ìƒˆë¡œìš´ ë°ì´í„° ë³‘í•©
        if new_data_frames:
            new_data = pd.concat(new_data_frames, ignore_index=True)
            
            # ì»¬ëŸ¼ëª… ì†Œë¬¸ìë¡œ ë³€í™˜
            new_data.columns = [col.lower() for col in new_data.columns]
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            if all(col in new_data.columns for col in ['open', 'high', 'low', 'close', 'volume']):
                new_data = new_data[['date', 'symbol', 'open', 'high', 'low', 'close', 'volume']]
            
            # ë‚ ì§œ í˜•ì‹ í†µì¼ (ëª¨ë“  ë‚ ì§œë¥¼ UTC ì‹œê°„ëŒ€ë¡œ ë³€í™˜)
            if not pd.api.types.is_datetime64tz_dtype(new_data["date"]):
                new_data["date"] = pd.to_datetime(new_data["date"], utc=True)
            
            # ë‚ ì§œ ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¤‘ë³µ ì œê±° (ì‹œê°„ëŒ€ ë¬¸ì œ í•´ê²°)
            df["date_str"] = df["date"].dt.strftime("%Y-%m-%d")
            new_data["date_str"] = new_data["date"].dt.strftime("%Y-%m-%d")
            
            # ê¸°ì¡´ ë°ì´í„°ì—ì„œ ìƒˆ ë°ì´í„°ì™€ ì¤‘ë³µë˜ëŠ” ë‚ ì§œ ì œê±°
            df_filtered = df[~df["date_str"].isin(new_data["date_str"])]
            
            # ë°ì´í„° ë³‘í•©
            df_combined = pd.concat([df_filtered, new_data], ignore_index=True)
            
            # ì„ì‹œ ì»¬ëŸ¼ ì œê±°
            df_combined.drop("date_str", axis=1, inplace=True)
            
            # ë‚ ì§œë¡œ ì •ë ¬
            df_combined = df_combined.sort_values('date')
            
            # ê²°ê³¼ ì €ì¥
            if output_file is None:
                output_file = csv_file
                
            # ê²°í•©ëœ ë°ì´í„° ì €ì¥
            df_combined.to_csv(output_file, index=False)
            # JSON íŒŒì¼ ìƒì„± ì¶”ê°€
            json_file = output_file.replace('.csv', '.json')
            df_combined.to_json(json_file, orient='records', indent=2, force_ascii=False)
            print(f"âœ… ì˜ì—…ì¼ ë°ì´í„° ì±„ì›€ ì™„ë£Œ: {os.path.basename(csv_file)} ({len(df)} â†’ {len(df_combined)} í–‰)")
            return True
        else:
            print(f"âš ï¸ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŒ: {os.path.basename(csv_file)}")
            return False
        
    except Exception as e:
        print(f"âŒ ì˜ì—…ì¼ ë°ì´í„° ì±„ìš°ê¸° ì˜¤ë¥˜: {csv_file} - {e}")
        return False

def process_all_csv_files(directory=DATA_US_DIR, max_workers=4):
    """
    ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  CSV íŒŒì¼ì— ëŒ€í•´ ì˜ì—…ì¼ ë°ì´í„° ì±„ìš°ê¸° í•¨ìˆ˜ë¥¼ ì‹¤í–‰
    
    Args:
        directory: CSV íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ
        max_workers: ìµœëŒ€ ë³‘ë ¬ ì‘ì—…ì ìˆ˜
        
    Returns:
        tuple: (ì„±ê³µ ìˆ˜, ì‹¤íŒ¨ ìˆ˜)
    """
    # ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  CSV íŒŒì¼ ì°¾ê¸°
    csv_files = glob.glob(os.path.join(directory, "*.csv"))
    
    if not csv_files:
        print(f"âš ï¸ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {directory}")
        return 0, 0
    
    print(f"ğŸ” ì´ {len(csv_files)}ê°œì˜ CSV íŒŒì¼ ì²˜ë¦¬ ì¤‘...")
    
    success_count = 0
    failure_count = 0
    
    # ë³‘ë ¬ ì²˜ë¦¬
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = list(executor.map(fill_missing_business_days_with_yfinance, csv_files))
    
    # ê²°ê³¼ ì§‘ê³„
    success_count = sum(1 for result in results if result)
    failure_count = sum(1 for result in results if not result)
    
    print(f"\nğŸ“Š ì²˜ë¦¬ ê²°ê³¼: ì„±ê³µ {success_count}, ì‹¤íŒ¨ {failure_count}")
    return success_count, failure_count

# ë©”ì¸ í•¨ìˆ˜
def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="ì˜ì—…ì¼ ë°ì´í„° ì±„ìš°ê¸° ë„êµ¬ (yfinance ì‚¬ìš© ë²„ì „)")
    parser.add_argument("--dir", type=str, default=DATA_US_DIR, help="CSV íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ")
    parser.add_argument("--workers", type=int, default=4, help="ë³‘ë ¬ ì‘ì—…ì ìˆ˜")
    parser.add_argument("--file", type=str, help="ë‹¨ì¼ CSV íŒŒì¼ ì²˜ë¦¬ (ì„ íƒ ì‚¬í•­)")
    
    args = parser.parse_args()
    
    if args.file:
        # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
        success = fill_missing_business_days_with_yfinance(args.file)
        if success:
            print("âœ… ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")
        else:
            print("âŒ ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨")
    else:
        # ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬
        success_count, failure_count = process_all_csv_files(args.dir, args.workers)
        if success_count > 0:
            print(f"âœ… {success_count}ê°œ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ, {failure_count}ê°œ ì‹¤íŒ¨")
        else:
            print(f"âŒ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ ({failure_count}ê°œ)")

if __name__ == "__main__":
    main()