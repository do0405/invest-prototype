#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì‹œì¥ í­(Market Breadth) ë°ì´í„° ìˆ˜ì§‘ê¸°

ì´ ëª¨ë“ˆì€ ë‹¤ìŒ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤:
- VIX (ë³€ë™ì„± ì§€ìˆ˜)
- Put/Call Ratio (ì˜µì…˜ ë°ì´í„°)
- High-Low Index (ì‹ ê³ ê°€/ì‹ ì €ê°€ ë¹„ìœ¨)
- Advance-Decline Line (ìƒìŠ¹/í•˜ë½ ì¢…ëª© ìˆ˜)
"""

import os
import sys
import pandas as pd
import yfinance as yf
from datetime import datetime, timedelta
import requests
from io import StringIO
from typing import Dict, Optional

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ import
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.screener_utils import read_csv_flexible

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import (
    BREADTH_DATA_DIR,
    OPTION_DATA_DIR,
    DATA_US_DIR,
    STOCK_METADATA_PATH,
)

class MarketBreadthCollector:
    """ì‹œì¥ í­ ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.ensure_directories()
        
    def ensure_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        os.makedirs(BREADTH_DATA_DIR, exist_ok=True)
        os.makedirs(OPTION_DATA_DIR, exist_ok=True)
        print(f"ğŸ“ ë°ì´í„° ë””ë ‰í† ë¦¬ í™•ì¸: {BREADTH_DATA_DIR}")
        print(f"ğŸ“ ì˜µì…˜ ë°ì´í„° ë””ë ‰í† ë¦¬ í™•ì¸: {OPTION_DATA_DIR}")
    
    def collect_vix_data(self, days: int = 252, force_update: bool = False) -> bool:
        """VIX ë°ì´í„° ìˆ˜ì§‘ (ìºì‹± ë° ì¤‘ë³µ ë°©ì§€)"""
        try:
            print("ğŸ“Š VIX ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            
            # ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(OPTION_DATA_DIR, exist_ok=True)
            vix_file = os.path.join(OPTION_DATA_DIR, 'vix.csv')
            
            # ê¸°ì¡´ íŒŒì¼ í™•ì¸ ë° ìºì‹± ë¡œì§
            if not force_update and os.path.exists(vix_file):
                try:
                    existing_data = pd.read_csv(vix_file)
                    if not existing_data.empty:
                        # ìµœì‹  ë°ì´í„°ê°€ 1ì¼ ì´ë‚´ì¸ì§€ í™•ì¸
                        last_date = pd.to_datetime(existing_data['date'].iloc[-1])
                        if (datetime.now() - last_date).days < 1:
                            print(f"âœ… ê¸°ì¡´ VIX ë°ì´í„° ì‚¬ìš© (ìµœì‹ : {last_date.date()})")
                            return True
                except Exception:
                    pass

            # VIX ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ì—¬ëŸ¬ ì‹œë„)
            vix = None
            symbols_to_try = ['^VIX', 'VIX']

            for symbol in symbols_to_try:
                try:
                    print(f"  ì‹œë„ ì¤‘: {symbol}")
                    vix = yf.download(symbol, period=f'{days}d', interval='1d', progress=False, auto_adjust=False)
                    if not vix.empty:
                        print(f"  âœ… {symbol}ì—ì„œ ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ")
                        break
                except Exception as e:
                    print(f"  âŒ {symbol} ì‹¤íŒ¨: {e}")
                    continue

            if vix is None or vix.empty:
                print('âŒ VIX ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')
                return False

            # VIX ë°ì´í„° ì •ë¦¬ ë° ê²€ì¦
            # MultiIndex ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
            if isinstance(vix.columns, pd.MultiIndex):
                vix.columns = vix.columns.droplevel(1)
            
            # ë°ì´í„° í‰íƒ„í™” ì²˜ë¦¬
            vix_close = vix['Close'].values.flatten() if hasattr(vix['Close'], 'values') else vix['Close']
            vix_high = vix['High'].values.flatten() if hasattr(vix['High'], 'values') else vix['High']
            vix_low = vix['Low'].values.flatten() if hasattr(vix['Low'], 'values') else vix['Low']
            vix_volume = vix['Volume'].values.flatten() if hasattr(vix['Volume'], 'values') else vix['Volume']
            
            vix_data = pd.DataFrame({
                'date': vix.index.strftime('%Y-%m-%d'),
                'vix_close': pd.Series(vix_close).round(2),
                'vix_high': pd.Series(vix_high).round(2),
                'vix_low': pd.Series(vix_low).round(2),
                'vix_volume': pd.Series(vix_volume).fillna(0).astype(int),
            })
            
            # ë°ì´í„° ê²€ì¦
            vix_data = vix_data.dropna(subset=['vix_close'])
            if vix_data.empty:
                print('âŒ ìœ íš¨í•œ VIX ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.')
                return False
            
            # íŒŒì¼ ì €ì¥
            vix_data.to_csv(vix_file, index=False)
            print(f"âœ… VIX ë°ì´í„° ì €ì¥ ì™„ë£Œ: {vix_file} ({len(vix_data)}ê°œ ë ˆì½”ë“œ)")
            print(f"  ìµœì‹  VIX: {vix_data.iloc[-1]['vix_close']} ({vix_data.iloc[-1]['date']})")
            
            return True
            
        except Exception as e:
            print(f"âŒ VIX ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return False
    
    # Put/Call Ratio ë°ì´í„° ìˆ˜ì§‘ ê¸°ëŠ¥ ì œê±°ë¨
    
    def _process_file_for_high_low(self, file_path: str, days: int, start_date: pd.Timestamp = None) -> Dict[pd.Timestamp, Dict[str, int]]:
        """Process a single file for high-low index calculation with incremental update support."""
        date_map: Dict[pd.Timestamp, Dict[str, int]] = {}
        try:
            df = read_csv_flexible(file_path, ['date', 'high', 'low', 'close'])
            if df is None:
                return date_map
            
            df['date'] = pd.to_datetime(df['date'], utc=True)
            df = df.sort_values('date')
            
            # ì¦ë¶„ ì—…ë°ì´íŠ¸ì¸ ê²½ìš° start_date ì´í›„ ë°ì´í„°ë§Œ ì²˜ë¦¬
            if start_date is not None:
                df_recent = df[df['date'] > start_date]
                if len(df_recent) == 0:
                    return date_map
                # 52ì£¼ ê³„ì‚°ì„ ìœ„í•´ ì¶©ë¶„í•œ ê³¼ê±° ë°ì´í„° í™•ë³´
                df_full = df.tail(252 + len(df_recent))
                process_days = len(df_recent)
            else:
                df_full = df.tail(252 + days)
                process_days = days

            for i in range(-process_days, 0):
                row = df_full.iloc[i]
                date = row['date']
                # ì¦ë¶„ ì—…ë°ì´íŠ¸ì¸ ê²½ìš° start_date ì´í›„ë§Œ ì²˜ë¦¬
                if start_date is not None and date <= start_date:
                    continue
                    
                window = df_full.iloc[: i + 252] if i != -process_days else df_full.iloc[:252]
                if len(window) < 50:  # ìµœì†Œ ë°ì´í„° ìš”êµ¬ì‚¬í•­
                    continue
                    
                high_52w = window['high'].max()
                low_52w = window['low'].min()
                record = date_map.setdefault(date, {'highs': 0, 'lows': 0, 'total': 0})
                if row['close'] >= high_52w:
                    record['highs'] += 1
                elif row['close'] <= low_52w:
                    record['lows'] += 1
                record['total'] += 1
        except Exception:
            pass
        return date_map

    def collect_high_low_index(self, days: int = 252) -> bool:
        """High-Low Index ë°ì´í„° ìˆ˜ì§‘ (ë³‘ë ¬ ì²˜ë¦¬)"""
        try:
            print("ğŸ“Š High-Low Index ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            
            # ê¸°ì¡´ ë°ì´í„° í™•ì¸
            hl_file = os.path.join(BREADTH_DATA_DIR, 'high_low_index.csv')
            existing_data = None
            last_date = None
            
            if os.path.exists(hl_file):
                existing_data = read_csv_flexible(hl_file, ['date'])
                if existing_data is not None:
                    try:
                        existing_data['date'] = pd.to_datetime(existing_data['date'], utc=True)
                        last_date = existing_data['date'].max()
                        print(f"âœ… ê¸°ì¡´ High-Low Index ë°ì´í„° í™•ì¸ (ìµœì‹ : {last_date.strftime('%Y-%m-%d')})")
                    except Exception as e:
                        print(f"âš ï¸ ë‚ ì§œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}, ì „ì²´ ì¬ìˆ˜ì§‘ ì§„í–‰")
                        existing_data = None
                        last_date = None
                else:
                    print(f"âš ï¸ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨, ì „ì²´ ì¬ìˆ˜ì§‘ ì§„í–‰")
                    existing_data = None
                    last_date = None
            
            # ì „ ì¢…ëª© ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ High-Low Index ê³„ì‚°
            csv_files = [
                os.path.join(DATA_US_DIR, f)
                for f in os.listdir(DATA_US_DIR)
                if f.endswith('.csv')
            ]

            if not csv_files:
                print('âŒ ì¢…ëª© ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
                return False

            print(f"ğŸ“ˆ {len(csv_files)}ê°œ íŒŒì¼ì„ ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë¶„ì„ ì¤‘...")
            
            # ì¦ë¶„ ì—…ë°ì´íŠ¸ ë°©ì‹ ê°œì„ : ëˆ„ë½ëœ ë°ì´í„°ë¶€í„° ì²˜ë¦¬
            from utils.incremental_update_helper import incremental_helper
            
            if last_date is not None:
                # ëˆ„ë½ëœ ê¸°ê°„ ê³„ì‚° (ê±°ë˜ì¼ ê¸°ì¤€ìœ¼ë¡œ ê°œì„ )
                from utils.incremental_update_helper import incremental_helper
                
                # í˜„ì¬ ì‹œê°„ì„ UTCë¡œ ì„¤ì •
                today = pd.Timestamp.now(tz='UTC')
                
                # ê±°ë˜ì¼ ê¸°ì¤€ìœ¼ë¡œ ëˆ„ë½ëœ ê¸°ê°„ í™•ì¸
                last_date_dt = last_date.to_pydatetime().replace(tzinfo=None)
                today_dt = today.to_pydatetime().replace(tzinfo=None)
                
                # ì˜¤ëŠ˜ì´ ê±°ë˜ì¼ì¸ì§€ í™•ì¸
                if incremental_helper.is_trading_day(today_dt):
                    # ì˜¤ëŠ˜ì´ ê±°ë˜ì¼ì´ë©´ ì˜¤ëŠ˜ê¹Œì§€ ë°ì´í„°ê°€ ìˆì–´ì•¼ í•¨
                    target_date = today_dt.date()
                else:
                    # ì˜¤ëŠ˜ì´ ê±°ë˜ì¼ì´ ì•„ë‹ˆë©´ ì´ì „ ê±°ë˜ì¼ê¹Œì§€ ë°ì´í„°ê°€ ìˆì–´ì•¼ í•¨
                    target_date = incremental_helper.get_previous_trading_day(today_dt).date()
                
                # ìµœì‹  ë°ì´í„°ê°€ ëª©í‘œ ë‚ ì§œì™€ ê°™ê±°ë‚˜ ì´í›„ë©´ ìµœì‹  ìƒíƒœ
                if last_date_dt.date() >= target_date:
                    print(f"ğŸ“ˆ ìµœì‹  ìƒíƒœ: {last_date.strftime('%Y-%m-%d')} (ëª©í‘œ: {target_date})")
                    return True
                
                # ëˆ„ë½ëœ ì¼ìˆ˜ ê³„ì‚°
                missing_days = (target_date - last_date_dt.date()).days
                update_days = min(missing_days + 2, days)  # ëˆ„ë½ëœ ì¼ìˆ˜ + 2ì¼ ì—¬ìœ 
                print(f"ğŸ“ˆ ì¦ë¶„ ì—…ë°ì´íŠ¸: {missing_days}ì¼ ëˆ„ë½, {update_days}ì¼ ì²˜ë¦¬ ì¤‘... (ëª©í‘œ: {target_date})")
            else:
                update_days = days
                print(f"ğŸ“ˆ ì „ì²´ ì—…ë°ì´íŠ¸: {len(csv_files)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì¤‘...")
            
            # ë³‘ë ¬ ì²˜ë¦¬ë¡œ íŒŒì¼ë“¤ ì²˜ë¦¬ (ì¦ë¶„ ì—…ë°ì´íŠ¸ ì§€ì›)
            from concurrent.futures import ThreadPoolExecutor, as_completed
            
            date_map: Dict[pd.Timestamp, Dict[str, int]] = {}
            all_file_results = []  # ëª¨ë“  íŒŒì¼ ê²°ê³¼ë¥¼ ì„ì‹œ ì €ì¥
            
            # ì¦ë¶„ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ì‹œì‘ ë‚ ì§œ ì„¤ì •
            start_date = last_date if last_date is not None else None
            
            # ìµœëŒ€ 8ê°œ ì›Œì»¤ë¡œ ë³‘ë ¬ ì²˜ë¦¬
            max_workers = min(8, len(csv_files))
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_file = {executor.submit(self._process_file_for_high_low, file, update_days, start_date): file for file in csv_files}
                
                completed = 0
                for future in as_completed(future_to_file):
                    file_result = future.result()
                    all_file_results.append(file_result)
                    completed += 1
                    if completed % 100 == 0 or (last_date is None and completed % 100 == 0):
                        print(f"ì§„í–‰ë¥ : {completed}/{len(csv_files)} íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")
            
            # ê²°ê³¼ ë³‘í•© (ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
            for file_result in all_file_results:
                for date, values in file_result.items():
                    if date not in date_map:
                        date_map[date] = {'highs': 0, 'lows': 0, 'total': 0}
                    date_map[date]['highs'] += values['highs']
                    date_map[date]['lows'] += values['lows']
                    date_map[date]['total'] += values['total']

            # ìƒˆë¡œìš´ ë°ì´í„° ìƒì„±
            new_hl_data = [
                {
                    'date': d,
                    'new_highs': v['highs'],
                    'new_lows': v['lows'],
                    'total_issues': v['total'],
                }
                for d, v in sorted(date_map.items())
            ]
            
            # ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©
            if existing_data is not None and len(new_hl_data) > 0:
                # ê¸°ì¡´ ë°ì´í„°ì—ì„œ ì¤‘ë³µ ë‚ ì§œ ì œê±°
                new_dates = set(pd.to_datetime([item['date'] for item in new_hl_data]))
                existing_filtered = existing_data[~existing_data['date'].isin(new_dates)]
                
                # ìƒˆ ë°ì´í„°ì™€ ê¸°ì¡´ ë°ì´í„° ê²°í•©
                new_df = pd.DataFrame(new_hl_data)
                new_df['date'] = pd.to_datetime(new_df['date'])
                hl_df = pd.concat([existing_filtered, new_df], ignore_index=True)
                hl_df = hl_df.sort_values('date').reset_index(drop=True)
                
                print(f"âœ… ì¦ë¶„ ì—…ë°ì´íŠ¸: {len(new_hl_data)}ê°œ ìƒˆ ë ˆì½”ë“œ ì¶”ê°€")
            else:
                # ì „ì²´ ì—…ë°ì´íŠ¸
                hl_df = pd.DataFrame(new_hl_data)
                if len(hl_df) > 0:
                    hl_df['date'] = pd.to_datetime(hl_df['date'])
            
            # íŒŒì¼ ì €ì¥
            if len(hl_df) > 0:
                hl_df.to_csv(hl_file, index=False)
                print(f"âœ… High-Low Index ë°ì´í„° ì €ì¥ ì™„ë£Œ: {hl_file} (ì´ {len(hl_df)}ê°œ ë ˆì½”ë“œ)")
            else:
                print("âš ï¸ ì €ì¥í•  ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            return True
            
        except Exception as e:
            print(f"âŒ High-Low Index ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return False
    
    def collect_advance_decline_data(self, days: int = 252) -> bool:
        """Advance-Decline ë°ì´í„°ë¥¼ ì‹¤ì œ ì¢…ëª© ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ ê³„ì‚° (ì¦ë¶„ ì—…ë°ì´íŠ¸)"""
        try:
            print("ğŸ“Š Advance-Decline ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            
            # ê¸°ì¡´ ë°ì´í„° í™•ì¸
            ad_file = os.path.join(BREADTH_DATA_DIR, 'advance_decline.csv')
            existing_data = None
            last_date = None
            
            if os.path.exists(ad_file):
                existing_data = read_csv_flexible(ad_file, ['date'])
                if existing_data is not None:
                    try:
                        existing_data['date'] = pd.to_datetime(existing_data['date'], utc=True)
                        last_date = existing_data['date'].max()
                        print(f"âœ… ê¸°ì¡´ Advance-Decline ë°ì´í„° í™•ì¸ (ìµœì‹ : {last_date.strftime('%Y-%m-%d')})")
                    except Exception as e:
                        print(f"âš ï¸ ë‚ ì§œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}, ì „ì²´ ì¬ìˆ˜ì§‘ ì§„í–‰")
                        existing_data = None
                        last_date = None
                else:
                    print(f"âš ï¸ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨, ì „ì²´ ì¬ìˆ˜ì§‘ ì§„í–‰")
                    existing_data = None
                    last_date = None

            csv_files = [
                os.path.join(DATA_US_DIR, f)
                for f in os.listdir(DATA_US_DIR)
                if f.endswith('.csv')
            ]

            if not csv_files:
                print('âŒ ì¢…ëª© ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
                return False

            # ì¦ë¶„ ì—…ë°ì´íŠ¸ ë°©ì‹ ê°œì„ : ëˆ„ë½ëœ ë°ì´í„°ë¶€í„° ì²˜ë¦¬
            if last_date is not None:
                # ëˆ„ë½ëœ ê¸°ê°„ ê³„ì‚° (ê±°ë˜ì¼ ê¸°ì¤€ìœ¼ë¡œ ê°œì„ )
                from utils.incremental_update_helper import incremental_helper
                
                # í˜„ì¬ ì‹œê°„ì„ UTCë¡œ ì„¤ì •
                today = pd.Timestamp.now(tz='UTC')
                
                # ê±°ë˜ì¼ ê¸°ì¤€ìœ¼ë¡œ ëˆ„ë½ëœ ê¸°ê°„ í™•ì¸
                last_date_dt = last_date.to_pydatetime().replace(tzinfo=None)
                today_dt = today.to_pydatetime().replace(tzinfo=None)
                
                # ì˜¤ëŠ˜ì´ ê±°ë˜ì¼ì¸ì§€ í™•ì¸
                if incremental_helper.is_trading_day(today_dt):
                    # ì˜¤ëŠ˜ì´ ê±°ë˜ì¼ì´ë©´ ì˜¤ëŠ˜ê¹Œì§€ ë°ì´í„°ê°€ ìˆì–´ì•¼ í•¨
                    target_date = today_dt.date()
                else:
                    # ì˜¤ëŠ˜ì´ ê±°ë˜ì¼ì´ ì•„ë‹ˆë©´ ì´ì „ ê±°ë˜ì¼ê¹Œì§€ ë°ì´í„°ê°€ ìˆì–´ì•¼ í•¨
                    target_date = incremental_helper.get_previous_trading_day(today_dt).date()
                
                # ìµœì‹  ë°ì´í„°ê°€ ëª©í‘œ ë‚ ì§œì™€ ê°™ê±°ë‚˜ ì´í›„ë©´ ìµœì‹  ìƒíƒœ
                if last_date_dt.date() >= target_date:
                    print(f"ğŸ“ˆ ìµœì‹  ìƒíƒœ: {last_date.strftime('%Y-%m-%d')} (ëª©í‘œ: {target_date})")
                    return True
                
                # ëˆ„ë½ëœ ì¼ìˆ˜ ê³„ì‚°
                missing_days = (target_date - last_date_dt.date()).days
                update_days = min(missing_days + 2, days)  # ëˆ„ë½ëœ ì¼ìˆ˜ + 2ì¼ ì—¬ìœ 
                print(f"ğŸ“ˆ ì¦ë¶„ ì—…ë°ì´íŠ¸: {missing_days}ì¼ ëˆ„ë½, {update_days}ì¼ ì²˜ë¦¬ ì¤‘... (ëª©í‘œ: {target_date})")
            else:
                update_days = days
                print(f"ğŸ“ˆ ì „ì²´ ì—…ë°ì´íŠ¸: {len(csv_files)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì¤‘...")

            date_map: Dict[pd.Timestamp, Dict[str, int]] = {}

            for file in csv_files:
                try:
                    df = read_csv_flexible(file, ['date', 'close'])
                    if df is None:
                        continue
                    
                    df['date'] = pd.to_datetime(df['date'], utc=True)
                    df = df.sort_values('date')
                    
                    # ì¦ë¶„ ì—…ë°ì´íŠ¸ì¸ ê²½ìš° í•„ìš”í•œ ë°ì´í„°ë§Œ ì²˜ë¦¬
                    if last_date is not None:
                        # ìµœì‹  ë‚ ì§œ ì´í›„ ë°ì´í„°ë§Œ ì²˜ë¦¬í•˜ë˜, ì´ì „ ë‚ ì§œ í•˜ë‚˜ëŠ” í¬í•¨ (ë¹„êµìš©)
                        cutoff_date = last_date - pd.Timedelta(days=2)  # 2ì¼ ì—¬ìœ ë¥¼ ë‘ 
                        df_filtered = df[df['date'] > cutoff_date]
                        if len(df_filtered) < 2:  # ë¹„êµí•  ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
                            continue
                        df = df_filtered
                    else:
                        df = df.tail(update_days + 1)
                    
                    for i in range(1, len(df)):
                        cur = df.iloc[i]
                        prev = df.iloc[i - 1]
                        date = cur['date']
                        
                        # ì¦ë¶„ ì—…ë°ì´íŠ¸ì¸ ê²½ìš° last_date ì´í›„ë§Œ ì²˜ë¦¬
                        if last_date is not None and date <= last_date:
                            continue
                            
                        rec = date_map.setdefault(date, {'advancing': 0, 'declining': 0, 'total': 0})
                        if pd.isna(cur['close']) or pd.isna(prev['close']):
                            continue
                        rec['total'] += 1
                        if cur['close'] > prev['close']:
                            rec['advancing'] += 1
                        elif cur['close'] < prev['close']:
                            rec['declining'] += 1
                except Exception:
                    continue

            # ìƒˆë¡œìš´ ë°ì´í„° ìƒì„±
            new_ad_data = [
                {
                    'date': d,
                    'advancing': v['advancing'],
                    'declining': v['declining'],
                    'unchanged': v['total'] - v['advancing'] - v['declining'],
                }
                for d, v in sorted(date_map.items())
            ]
            
            # ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©
            if existing_data is not None and len(new_ad_data) > 0:
                # ê¸°ì¡´ ë°ì´í„°ì—ì„œ ì¤‘ë³µ ë‚ ì§œ ì œê±°
                new_dates = set(pd.to_datetime([item['date'] for item in new_ad_data]))
                existing_filtered = existing_data[~existing_data['date'].isin(new_dates)]
                
                # ìƒˆ ë°ì´í„°ì™€ ê¸°ì¡´ ë°ì´í„° ê²°í•©
                new_df = pd.DataFrame(new_ad_data)
                new_df['date'] = pd.to_datetime(new_df['date'])
                ad_df = pd.concat([existing_filtered, new_df], ignore_index=True)
                ad_df = ad_df.sort_values('date').reset_index(drop=True)
                
                print(f"âœ… ì¦ë¶„ ì—…ë°ì´íŠ¸: {len(new_ad_data)}ê°œ ìƒˆ ë ˆì½”ë“œ ì¶”ê°€")
            else:
                # ì „ì²´ ì—…ë°ì´íŠ¸
                ad_df = pd.DataFrame(new_ad_data)
                if len(ad_df) > 0:
                    ad_df['date'] = pd.to_datetime(ad_df['date'])
            
            # ë°ì´í„° ê²€ì¦ ë° ì²˜ë¦¬
            if len(new_ad_data) == 0:
                print("âš ï¸ ìƒˆë¡œìš´ Advance-Decline ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                if existing_data is not None:
                    print(f"âœ… ê¸°ì¡´ ë°ì´í„° ìœ ì§€: {len(existing_data)}ê°œ ë ˆì½”ë“œ")
                    return True
                else:
                    # ë¹ˆ DataFrameì´ë¼ë„ ê¸°ë³¸ êµ¬ì¡°ëŠ” ìœ ì§€
                    ad_df = pd.DataFrame(columns=['date', 'advancing', 'declining', 'unchanged'])
            else:
                # ë°ì´í„° íƒ€ì… í™•ì¸ ë° ë³€í™˜
                if 'ad_df' in locals() and not ad_df.empty:
                    for col in ['advancing', 'declining', 'unchanged']:
                        if col in ad_df.columns:
                            ad_df[col] = pd.to_numeric(ad_df[col], errors='coerce').fillna(0).astype(int)
            
            # íŒŒì¼ ì €ì¥
            ad_file = os.path.join(BREADTH_DATA_DIR, 'advance_decline.csv')
            if 'ad_df' in locals() and len(ad_df) > 0:
                ad_df.to_csv(ad_file, index=False)
                print(f"âœ… Advance-Decline ë°ì´í„° ì €ì¥ ì™„ë£Œ: {ad_file} (ì´ {len(ad_df)}ê°œ ë ˆì½”ë“œ)")
            else:
                print("âš ï¸ ì €ì¥í•  ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            return True
            
        except Exception as e:
            print(f"âŒ Advance-Decline ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return False
    
    def collect_all_data(self, days: int = 252) -> Dict[str, bool]:
        """ëª¨ë“  ì‹œì¥ í­ ë°ì´í„° ìˆ˜ì§‘"""
        print("ğŸš€ ì‹œì¥ í­ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        print(f"ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: ìµœê·¼ {days}ì¼")
        print("="*50)
        
        results = {
            'vix': self.collect_vix_data(days),
            'high_low_index': self.collect_high_low_index(days),
            'advance_decline': self.collect_advance_decline_data(days)
        }
        
        print("="*50)
        print("ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ê²°ê³¼:")
        for data_type, success in results.items():
            status = "âœ… ì„±ê³µ" if success else "âŒ ì‹¤íŒ¨"
            print(f"  {data_type}: {status}")
        
        success_count = sum(results.values())
        total_count = len(results)
        print(f"\nğŸ¯ ì „ì²´ ê²°ê³¼: {success_count}/{total_count} ì„±ê³µ")
        
        return results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    collector = MarketBreadthCollector()
    results = collector.collect_all_data(days=252)  # 1ë…„ì¹˜ ë°ì´í„°
    
    if all(results.values()):
        print("\nğŸ‰ ëª¨ë“  ì‹œì¥ í­ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
        return True
    else:
        print("\nâš ï¸ ì¼ë¶€ ë°ì´í„° ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return False

if __name__ == "__main__":
    main()
