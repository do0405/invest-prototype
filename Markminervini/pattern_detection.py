# VCP ë° Cup-with-Handle íŒ¨í„´ íƒì§€ ëª¨ë“ˆ
# ê¸°ê³„í•™ìŠµ ì—†ì´ ë£° ê¸°ë°˜ìœ¼ë¡œ íŒ¨í„´ì„ ì‹ë³„í•˜ê³  ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ ê³„ì‚°

import os
import pandas as pd
import numpy as np
from scipy.signal import find_peaks, argrelextrema
from scipy.stats import linregress, gaussian_kde
from statsmodels.nonparametric.kernel_regression import KernelReg
import warnings
from datetime import datetime, timedelta
import yfinance as yf
from sklearn.preprocessing import MinMaxScaler
import traceback
warnings.filterwarnings('ignore')

class ContractionAnalyzer:
    def __init__(self):
        pass
        
    def calculate_atr(self, high, low, close, length=14):
        """ATR(Average True Range) ê³„ì‚°"""
        try:
            tr = pd.DataFrame()
            tr['h-l'] = high - low
            tr['h-pc'] = abs(high - close.shift(1))
            tr['l-pc'] = abs(low - close.shift(1))
            tr['tr'] = tr[['h-l', 'h-pc', 'l-pc']].max(axis=1)
            return tr['tr'].rolling(length).mean()
        except Exception as e:
            print(f"ATR ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print(traceback.format_exc())
            return pd.Series()

    def analyze_contraction_signals(self, df):
        """5ê°€ì§€ ìˆ˜ì¶• ì‹ í˜¸ ë¶„ì„"""
        try:
            vol = df['volume']
            high, low = df['high'], df['low']
            close = df['close']
            
            # â‘  VDU (Volume Dry-Up)
            v10 = vol.tail(10).mean()
            v50 = vol.ewm(span=50).mean().iloc[-1]
            vdu = v10 < 0.4 * v50
            
            # â‘¡ ê°€ê²© ë²”ìœ„ ìˆ˜ì¶•
            range_now = (high - low).tail(5).mean()
            range_prev = (high - low).tail(10).head(5).mean()
            pr_contr = range_now < 0.8 * range_prev
            
            # â‘¢ ATR ìˆ˜ì¶•
            atr = self.calculate_atr(high, low, close)
            atr_contr = atr.iloc[-1] < 0.8 * atr.iloc[-15]
        
            # â‘£ ê±°ë˜ëŸ‰ í•˜ë½ ì¶”ì„¸
            y = np.log1p(vol.tail(20).values)
            slope, _ = np.polyfit(np.arange(20), y, 1)
            std_ratio = y.std() / y.mean()
            vol_down = (slope < -0.001) and (std_ratio < 0.2)
        
            # â‘¤ Higher Lows
            lows = low.tail(3).values
            higher_lows = lows[0] < lows[1] < lows[2]
            
            # ì ìˆ˜ ê³„ì‚° (30ì  ë§Œì )
            score = (
                5 * vdu +
                5 * pr_contr +
                5 * atr_contr +
                10 * vol_down +
                5 * higher_lows
            )
            
            return {
                'score': score,
                'signals': {
                    'VDU': vdu,
                    'PriceRange': pr_contr,
                    'ATRContract': atr_contr,
                    'VolDowntrend': vol_down,
                    'HigherLows': higher_lows
                }
            }
        except Exception as e:
            print(f"ìˆ˜ì¶• ì‹ í˜¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print(traceback.format_exc())
            return {'score': 0, 'signals': {}}

def analyze_tickers_from_results(results_dir, data_dir, output_dir='../results2'):
    """advanced_financial_results.csvì—ì„œ í‹°ì»¤ë¥¼ ê°€ì ¸ì™€ ìˆ˜ì¶• ì‹ í˜¸ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    try:
        # results2 ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)
        print(f"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±/í™•ì¸: {output_dir}")
        
        # advanced_financial_results.csv íŒŒì¼ ì¡´ì¬ í™•ì¸
        results_file = os.path.join(results_dir, 'advanced_financial_results.csv')
        if not os.path.exists(results_file):
            raise FileNotFoundError(f"ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {results_file}")
        
        results_df = pd.read_csv(results_file)
        analyzer = ContractionAnalyzer()
        analysis_results = []
        
        total_tickers = len(results_df)
        print(f"ğŸ“Š {total_tickers}ê°œ ì¢…ëª© ë¶„ì„ ì‹œì‘...")
        
        for idx, row in results_df.iterrows():
            try:
                symbol = row['symbol']
                fin_met_count = row['fin_met_count']
                rs_score = row['rs_score']
                
                # ì§„í–‰ ìƒí™© í‘œì‹œ
                if (idx + 1) % 100 == 0:
                    print(f"â³ ì§„í–‰ ì¤‘: {idx + 1}/{total_tickers} ì¢…ëª© ì²˜ë¦¬ë¨")
                
                # fin_met_countê°€ 5 ë¯¸ë§Œì¸ ê²½ìš° ê±´ë„ˆë›°ê¸°
                if fin_met_count < 5:
                    continue
                    
                file_path = os.path.join(data_dir, f'{symbol}.csv')
                if not os.path.exists(file_path):
                    print(f"âš ï¸ {symbol} ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
                    continue
                    
                df = pd.read_csv(file_path)
                
                # ì»¬ëŸ¼ëª… í™•ì¸ ë° ì²˜ë¦¬
                date_column = None
                for col in df.columns:
                    if col.lower() in ['date', 'ë‚ ì§œ', 'ì¼ì']:
                        date_column = col
                        break
                
                if date_column is None:
                    print(f"âš ï¸ {symbol} ë°ì´í„°ì—ì„œ ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì»¬ëŸ¼: {df.columns.tolist()}")
                    continue
                
                # ë‚ ì§œ ì»¬ëŸ¼ì„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
                df[date_column] = pd.to_datetime(df[date_column])
                df.set_index(date_column, inplace=True)
                
                # ì»¬ëŸ¼ëª… ë§¤í•‘ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´)
                column_mapping = {
                    'high': ['high', 'high', 'ê³ ê°€'],
                    'low': ['low', 'low', 'ì €ê°€'],
                    'close': ['close', 'close', 'ì¢…ê°€'],
                    'volume': ['volume', 'volume', 'ê±°ë˜ëŸ‰']
                }
                
                # ì»¬ëŸ¼ëª… ì°¾ê¸°
                found_columns = {}
                for required_col, possible_names in column_mapping.items():
                    for col in df.columns:
                        if col.lower() in [name.lower() for name in possible_names]:
                            found_columns[required_col] = col
                            break
                
                # í•„ìš”í•œ ì»¬ëŸ¼ì´ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸
                missing_columns = [col for col in column_mapping.keys() if col not in found_columns]
                if missing_columns:
                    print(f"âš ï¸ {symbol} ë°ì´í„°ì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {missing_columns}")
                    print(f"í˜„ì¬ ì»¬ëŸ¼: {df.columns.tolist()}")
                    continue
                
                # ì»¬ëŸ¼ëª… ë³€ê²½
                df = df.rename(columns={v: k for k, v in found_columns.items()})
                
                result = analyzer.analyze_contraction_signals(df)
                
                # contraction_scoreê°€ 5ì  ì´í•˜ì¸ ê²½ìš° ê±´ë„ˆë›°ê¸°
                if result['score'] <= 5:
                    continue
                
                analysis_results.append({
                    'symbol': symbol,
                    'rs_score': rs_score,
                    'contraction_score': result['score'],
                    'fin_met_count': fin_met_count,
                    'VDU': result['signals'].get('VDU', False),
                    'PriceRange': result['signals'].get('PriceRange', False),
                    'ATRContract': result['signals'].get('ATRContract', False),
                    'VolDowntrend': result['signals'].get('VolDowntrend', False),
                    'HigherLows': result['signals'].get('HigherLows', False)
                })
            except Exception as e:
                print(f"âš ï¸ {symbol} ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                print(traceback.format_exc())
                continue
        
        if not analysis_results:
            print("âŒ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        results_df = pd.DataFrame(analysis_results)
        # ìˆ˜ì¶• ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        results_df = results_df.sort_values('contraction_score', ascending=False)
        
        # ê²°ê³¼ ì €ì¥
        output_file = os.path.join(output_dir, 'pattern_analysis_results.csv')
        # ê²°ê³¼ ì €ì¥
        results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
        # JSON íŒŒì¼ ìƒì„± ì¶”ê°€
        json_file = output_file.replace('.csv', '.json')
        results_df.to_json(json_file, orient='records', indent=2, force_ascii=False)
        print(f"âœ… ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
        
        return results_df
        
    except Exception as e:
        print(f"âŒ íŒ¨í„´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(traceback.format_exc())
        return pd.DataFrame()

# ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€ë¥¼ ìœ„í•´ main í•¨ìˆ˜ì™€ ì§ì ‘ ì‹¤í–‰ ì½”ë“œ ì œê±°
# def main():
#     """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
#     try:
#         results_dir = '../results'
#         data_dir = '../data_us'
#         output_dir = '../results2'
#         
#         analyze_tickers_from_results(results_dir, data_dir, output_dir)
#         
#     except Exception as e:
#         print(f"âŒ ë©”ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
#         print(traceback.format_exc())

# if __name__ == "__main__":
#     main()